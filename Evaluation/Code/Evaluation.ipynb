{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "538ba698",
   "metadata": {},
   "source": [
    "In this notebook, we evaluate the latest version of the **Anaouder Vosk model** on the dataset \"La banque sonore des dialectes bretons\":\n",
    "* The dataset audio files are already in wav format, so no need to use the function `MP3toWAV`\n",
    "\n",
    "* However, for the compatibility with Vosk model, all audio files must be converted to a 16 kHz sampling rate with the function `resample_all_wav`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f4d2ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wave\n",
    "import json\n",
    "import jiwer\n",
    "import vosk \n",
    "from vosk import Model, KaldiRecognizer\n",
    "import audio\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6deabff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53c2f576",
   "metadata": {},
   "outputs": [],
   "source": [
    "from audio import resample_all_wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a539822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the dataset\n",
    "dataset_path = \"/home/ouassim/Desktop/stage/Kaldi/kaldi/data/test/\"\n",
    "output_path = \"/home/ouassim/Desktop/stage/evaluation/Code/test_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b8d0ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6918e40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = output_path\n",
    "model_path = \"/home/ouassim/Desktop/stage/Anaouder model/vosk-model-br-25 .02/vosk-model-br-25.02\"\n",
    "ground_truth_path = \"/home/ouassim/Desktop/stage/Kaldi/kaldi/data/test/text\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2975554",
   "metadata": {},
   "source": [
    "* One problem of this dataset is that due to bad scrapping from the web source, it contains a mix of utterances in both Standard Breton and Dialectal Breton, which may affect the model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44cf275c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOG (VoskAPI:ReadDataFiles():model.cc:213) Decoding params beam=13 max-active=7000 lattice-beam=6\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:216) Silence phones 1:2:3:4:5:6:7:8:9:10\n",
      "LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.\n",
      "LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:248) Loading i-vector extractor from /home/ouassim/Desktop/stage/Anaouder model/vosk-model-br-25 .02/vosk-model-br-25.02/ivector/final.ie\n",
      "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor\n",
      "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:279) Loading HCLG from /home/ouassim/Desktop/stage/Anaouder model/vosk-model-br-25 .02/vosk-model-br-25.02/HCLG.fst\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:297) Loading words from /home/ouassim/Desktop/stage/Anaouder model/vosk-model-br-25 .02/vosk-model-br-25.02/words.txt\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:308) Loading winfo /home/ouassim/Desktop/stage/Anaouder model/vosk-model-br-25 .02/vosk-model-br-25.02/word_boundary.int\n"
     ]
    }
   ],
   "source": [
    "model = Model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c3e282",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c36ceda0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Missing dictionary file first_names.tsv\n",
      "Missing dictionary file last_names.tsv\n",
      "Missing dictionary file places.tsv\n",
      "Missing dictionary file proper_nouns_phon.tsv\n",
      "Missing dictionary file countries_phon.tsv\n",
      "Missing dictionary file adjectives.tsv\n",
      "Missing dictionary file acronyms.tsv\n",
      "Missing dictionary file abbreviations.tsv\n",
      "Missing dictionary file interjections.tsv\n",
      "Missing dictionary file corrected_tokens.tsv\n",
      "Missing dictionary file standard_tokens.tsv\n",
      "Missing dictionary file stopwords.tsv\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'text.utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtranscriber\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transcribe_audio\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mevaluatee\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m evaluate_wer, evaluate_cer\n",
      "File \u001b[0;32m~/Desktop/stage/evaluation/Code/evaluatee.py:13\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfilter_char\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m filter_out_chars\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnormalizer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m normalize_sentence\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Function to evaluate WER for the entire dataset\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_wer\u001b[39m(dataset_path, ground_truth_dict, model):\n",
      "File \u001b[0;32m~/Desktop/stage/evaluation/Code/normalizer.py:7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#! /usr/bin/env python3\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Iterator, List, Any\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtext\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdefinitions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      8\u001b[0m     SI_UNITS,\n\u001b[1;32m      9\u001b[0m     ORDINALS, match_ordinal,\n\u001b[1;32m     10\u001b[0m     ROMAN_ORDINALS, match_roman_ordinal,\n\u001b[1;32m     11\u001b[0m     )\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtext\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokenizer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tokenize, detokenize, Token, TokenType\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnouns_f\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mnouns_m\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/stage/evaluation/Code/text/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Iterator, Any\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokenizer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Token, tokenize, detokenize, split_sentences, split_sentences_old\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnormalizer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m normalize, normalize_sentence\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minverse_normalizer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m inverse_normalize_sentence, inverse_normalize_timecoded\n",
      "File \u001b[0;32m~/Desktop/stage/evaluation/Code/text/tokenizer.py:27\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_splitter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceSplitter, split_text_into_sentences\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdefinitions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     17\u001b[0m     re_word, is_word, is_word_inclusive, re_extended_word,\n\u001b[1;32m     18\u001b[0m     is_roman_number, is_ordinal, is_roman_ordinal,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     25\u001b[0m     PUNCT_PAIRS, OPENING_PUNCT, CLOSING_PUNCT,\n\u001b[1;32m     26\u001b[0m )\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m capitalize, is_capitalized\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdicts\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     29\u001b[0m     acronyms,\n\u001b[1;32m     30\u001b[0m     abbreviations,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     34\u001b[0m     dicts\n\u001b[1;32m     35\u001b[0m )\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mTokenType\u001b[39;00m(Enum):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'text.utils'"
     ]
    }
   ],
   "source": [
    "from load_ground_truth import load_ground_truth_dict\n",
    "\n",
    "from transcriber import transcribe_audio\n",
    "\n",
    "import sys\n",
    "\n",
    "from evaluatee import evaluate_wer, evaluate_cer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1478413f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_dict = load_ground_truth_dict(ground_truth_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9767d90",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'evaluate_wer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mevaluate_wer\u001b[49m(dataset_path, ground_truth_dict, model)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'evaluate_wer' is not defined"
     ]
    }
   ],
   "source": [
    "evaluate_wer(dataset_path, ground_truth_dict, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5c68d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stt-breton",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
